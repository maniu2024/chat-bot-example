
spring:
  ai:
    ollama:
      base-url: http://localhost:11434
      chat:
        options:
          temperature: 0.8
          model: qwen2
          repeat-penalty: 1.2
      embedding:
        model: mofanke/acge_text_embedding
  data:
    redis:
      host: localhost
      port: 6379
      lettuce:
        pool:
          enabled: true
server:
  port: 6000
logging:
  level:
    org.springframework.ai.chat.client.advisor: debug



retriever:
  web:
    tavily:
      base_url: https://api.tavily.com/search
      api_key: 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
